# ğŸ•¹ MarioRL

![Imagem de Fundo](data/mariofundo.png)

## ğŸ¯ DescriÃ§Ã£o

**MarioRL** Ã© um agente de **Aprendizado por ReforÃ§o** desenvolvido para aprender a jogar **Super Mario Bros** de forma autÃ´noma. Utilizando tÃ©cnicas avanÃ§adas de aprendizado profundo e otimizaÃ§Ãµes eficientes, MarioRL busca alcanÃ§ar um desempenho comparÃ¡vel aos modelos mais robustos com uma fraÃ§Ã£o dos parÃ¢metros.

## ğŸ§  Algoritmos de Aprendizado

### 1. **Rede de Q-Duplo com Dueling**
- **TÃ©cnica avanÃ§ada de aprendizado profundo**: Combina redes neurais duplas para estimar os valores de aÃ§Ã£o de maneira mais precisa.
- **Melhora a eficiÃªncia de aprendizagem**: Reduz o viÃ©s na estimativa do valor de aÃ§Ã£o, promovendo um aprendizado mais estÃ¡vel e eficiente.

### 2. **OtimizaÃ§Ã£o de PolÃ­tica Proximal**
- **EstratÃ©gia robusta de melhoria de polÃ­tica**: Garante atualizaÃ§Ãµes de polÃ­tica seguras, evitando grandes mudanÃ§as que possam degradar o desempenho.
- **DinÃ¢micas de aprendizado estÃ¡veis**: Promove um treinamento mais consistente e confiÃ¡vel, facilitando a convergÃªncia do agente.

## â–¶ ExecuÃ§Ã£o do Projeto

### ğŸƒâ€â™‚ï¸ Avaliar Agente PrÃ©-treinado

Para avaliar o desempenho do agente treinado, execute o script de teste:

```bash
python test.py

```

### ğŸš´â€â™‚ï¸ Treinar Novo Agente
Para iniciar o processo de treinamento de um novo agente, utilize o seguinte comando:

```bash
python train.py
```

### ğŸ““ ExploraÃ§Ã£o Interativa
Explore o Jupyter Notebook para visualizar e interagir com o projeto de forma mais detalhada:

### [Jupyter Notebook](MarioRL.ipynb)
